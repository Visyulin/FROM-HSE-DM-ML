{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ml_theme.png\">\n",
    "# Дополнительное профессиональное <br> образование НИУ ВШЭ\n",
    "#### Программа \"Машинное обучение и майнинг данных\"\n",
    "<img src=\"../../img/faculty_logo.jpg\" height=\"240\" width=\"240\">\n",
    "## Автор материала: преподаватель Факультета Компьютерных Наук НИУ ВШЭ Кашницкий Юрий\n",
    "</center>\n",
    "Материал распространяется на условиях лицензии <a href=\"https://opensource.org/licenses/MS-RL\">Ms-RL</a>. Можно использовать в любых целях, кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание № 6. Часть 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1.\n",
    "Дан список слов. Написать функцию *count_in_word_list*, возвращающую словарь вида {word: word_count}. Использовать функцию map и собственные функции my_reduce и shuffle, которая будет группировать пары (ключ, значение) по ключам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_reduce # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_in_word_list(word_list):\n",
    "    return reduce(my_reduce, # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert count_in_word_list([]) == {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert count_in_word_list(['apple']) == {'apple': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert count_in_word_list(['a', 'friend', 'in', 'need',\n",
    "                          'is', 'a', 'friend', 'indeed']) == {'a': 2, 'friend': 2,\n",
    "                                                            'in': 1, 'need': 1,\n",
    "                                                            'is': 1, 'indeed': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В *ML_DM_AddProfEduc/data/chapters_tom_sawyer* находятся несколько файлов - главы из Тома Сойера. Считая эти файлы маленькими, то есть помещающимися в память одной машины (а так оно и есть), посчитайте частоты слов в каждом файле, а потом и во всех 5 файлах. Используйте функцию из задачи 1. \n",
    "При чтении данных исключайте стоп-слова и пустые слова. Скачайте список стоп-слов с помощью nltk (входит в сборку Anaconda, используйте nltk.download и nltk.corpus.stopwords.words). Лемматизация и прочий парсинг - по желанию.\n",
    "Выведите топ-20 самых частых слов во всех 5 файлах (в виде DataFrame). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_file(filename):\n",
    "    words = []\n",
    "    \n",
    "    # Ваш код здесь\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = glob('../../data/chapters_tom_sawyer/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_dics = # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_word_dic = reduce # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_freq_df = pd.DataFrame.from_dict # Ваш код здесь\n",
    "word_freq_df.columns=['freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_freq_df.sort(columns=['freq'], ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
