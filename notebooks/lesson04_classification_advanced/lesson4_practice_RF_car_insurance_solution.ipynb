{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<center>\n",
    "<img src=\"../../img/ml_theme.png\">\n",
    "# Дополнительное профессиональное <br> образование НИУ ВШЭ\n",
    "#### Программа \"Машинное обучение и майнинг данных\"\n",
    "<img src=\"../../img/faculty_logo.jpg\" height=\"240\" width=\"240\">\n",
    "## Автор материала: преподаватель Факультета Компьютерных Наук НИУ ВШЭ Кашницкий Юрий\n",
    "</center>\n",
    "Материал распространяется на условиях лицензии <a href=\"https://opensource.org/licenses/MS-RL\">Ms-RL</a>. Можно использовать в любых целях, кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Занятие 4. Продвинутые методы классификации и регрессии. Переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Практика. Случайный лес в соревновании Kaggle Inclass по автострахованию. Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Соревнование](https://inclass.kaggle.com/c/hse-addprofeduc-ml-contest), исходное <a href=\"http://microsoftbi.ru/2015/06/06/hackathon2015ml/\">описание</a> задачи. \n",
    "\n",
    "Задача бинарной классификации. Имеются автомобили, для которых указан регистрационный номер и марка, и выплаты страховой компании по инцидентам с участием данного автомобиля. Страховая компания для себя решает, много она заплатила или мало. \n",
    "\n",
    "Объекты - автомобили.\n",
    "\n",
    "Признаки:\n",
    "\n",
    "- Регистрационный номер автомобиля (auto_number, уникальный, строка)\n",
    "- Марка автомобиля (auto_brand, строка)\n",
    "- Тип выплаты (too_much) (много/мало, 1 или 0)\n",
    "- Сумма выплаты при попадании водителя в аварию (compensated, целое положительное число)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и первичный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%pylab inline\n",
    "figsize(12, 8)\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sys\n",
    "sys.path.append('../../scripts/')\n",
    "from load_car_insurance_with_region import load_train_and_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считаем обучающую и тестовую выборку, создав объекты Pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df, y, test_df = load_train_and_test('../../data/car_insurance_train.csv',\n",
    "                                          '../../data/car_insurance_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto_brand</th>\n",
       "      <th>compensated</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3200</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6500</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    auto_brand  compensated  region\n",
       "id                                 \n",
       "1            2         3200      21\n",
       "2            5         6500      12\n",
       "3            2         2100       9\n",
       "4            2         2000       4\n",
       "5            2         6100      21"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Продвинутый\" подход для работы с категориальными признаками - это считать статистики (например, max, min, median, квантили и т.д.) количественных признаков по категориальным. Для этого удобно использовать метод groupby pandas.DataFrame (при необходимости посмотрите документацию метода).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#?train_df.groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример. Считаем средние выплаты для каждой марки авто отдельно. Видно, что для разных марок средние выплаты могут существенно отличаться.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_comp_by_brand = {brand_cat[0]: brand_cat[1]['compensated'].mean() \n",
    "                      for brand_cat in train_df.groupby(\"auto_brand\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 4200.0,\n",
       " 1.0: 3366.6666666666665,\n",
       " 2.0: 7498.480243161094,\n",
       " 3.0: 14312.5,\n",
       " 4.0: 9988.235294117647,\n",
       " 5.0: 7305.882352941177,\n",
       " 6.0: 10672.222222222223,\n",
       " 7.0: 5533.333333333333,\n",
       " 8.0: 15162.5,\n",
       " 9.0: 9442.857142857143,\n",
       " 10.0: 5823.809523809524,\n",
       " 11.0: 3100.0,\n",
       " 12.0: 8500.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_comp_by_brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте признаки \"Медианные выплаты по маркам\", \"Средние выплаты по регионам\" и т.п. (используйте функцию groupby). Посчитайте статистики mean, median, min и max (можно, конечно, и написать функцию, которая считает заданную статистику для заданного признака). Получится 8 новых признаков. После этого удалите исходные признаки auto_brand и region.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_comp_by_brand = {brand_cat[0]: brand_cat[1]['compensated'].mean() for brand_cat in train_df.groupby(\"auto_brand\")}\n",
    "median_comp_by_brand = {brand_cat[0]: brand_cat[1]['compensated'].median() for brand_cat in train_df.groupby(\"auto_brand\")}\n",
    "min_comp_by_brand = {brand_cat[0]: brand_cat[1]['compensated'].min() for brand_cat in train_df.groupby(\"auto_brand\")}\n",
    "max_comp_by_brand = {brand_cat[0]: brand_cat[1]['compensated'].max() for brand_cat in train_df.groupby(\"auto_brand\")}\n",
    "\n",
    "mean_comp_by_region = {brand_cat[0]: brand_cat[1]['compensated'].mean() for brand_cat in train_df.groupby(\"region\")}\n",
    "median_comp_by_region = {brand_cat[0]: brand_cat[1]['compensated'].median() for brand_cat in train_df.groupby(\"region\")}\n",
    "min_comp_by_region = {brand_cat[0]: brand_cat[1]['compensated'].min() for brand_cat in train_df.groupby(\"region\")}\n",
    "max_comp_by_region = {brand_cat[0]: brand_cat[1]['compensated'].max() for brand_cat in train_df.groupby(\"region\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['mean_by_brand'] = [mean_comp_by_brand[i] for i in train_df['auto_brand']]\n",
    "test_df['mean_by_brand'] = [mean_comp_by_brand[i] for i in test_df['auto_brand']]\n",
    "train_df['median_by_brand'] = [median_comp_by_brand[i] for i in train_df['auto_brand']]\n",
    "test_df['median_by_brand'] = [median_comp_by_brand[i] for i in test_df['auto_brand']]\n",
    "train_df['min_by_brand'] = [min_comp_by_brand[i] for i in train_df['auto_brand']]\n",
    "test_df['min_by_brand'] = [min_comp_by_brand[i] for i in test_df['auto_brand']]\n",
    "train_df['max_by_brand'] = [max_comp_by_brand[i] for i in train_df['auto_brand']]\n",
    "test_df['max_by_brand'] = [max_comp_by_brand[i] for i in test_df['auto_brand']]\n",
    "\n",
    "train_df['mean_by_region'] = [mean_comp_by_region[i] for i in train_df['region']]\n",
    "test_df['mean_by_region'] = [mean_comp_by_region[i] for i in test_df['region']]\n",
    "train_df['median_by_region'] = [median_comp_by_region[i] for i in train_df['region']]\n",
    "test_df['median_by_region'] = [median_comp_by_region[i] for i in test_df['region']]\n",
    "train_df['min_by_region'] = [min_comp_by_region[i] for i in train_df['region']]\n",
    "test_df['min_by_region'] = [min_comp_by_region[i] for i in test_df['region']]\n",
    "train_df['max_by_region'] = [max_comp_by_region[i] for i in train_df['region']]\n",
    "test_df['max_by_region'] = [max_comp_by_region[i] for i in test_df['region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto_brand</th>\n",
       "      <th>compensated</th>\n",
       "      <th>region</th>\n",
       "      <th>mean_by_brand</th>\n",
       "      <th>median_by_brand</th>\n",
       "      <th>min_by_brand</th>\n",
       "      <th>max_by_brand</th>\n",
       "      <th>mean_by_region</th>\n",
       "      <th>median_by_region</th>\n",
       "      <th>min_by_region</th>\n",
       "      <th>max_by_region</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3200</td>\n",
       "      <td>21</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>8638.888889</td>\n",
       "      <td>3100</td>\n",
       "      <td>100</td>\n",
       "      <td>103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6500</td>\n",
       "      <td>12</td>\n",
       "      <td>7305.882353</td>\n",
       "      <td>6500</td>\n",
       "      <td>500</td>\n",
       "      <td>22400</td>\n",
       "      <td>5608.333333</td>\n",
       "      <td>5000</td>\n",
       "      <td>1100</td>\n",
       "      <td>13000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2100</td>\n",
       "      <td>9</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>5650.000000</td>\n",
       "      <td>4700</td>\n",
       "      <td>500</td>\n",
       "      <td>18800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>2587.692308</td>\n",
       "      <td>1500</td>\n",
       "      <td>100</td>\n",
       "      <td>46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>6100</td>\n",
       "      <td>21</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>8638.888889</td>\n",
       "      <td>3100</td>\n",
       "      <td>100</td>\n",
       "      <td>103600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    auto_brand  compensated  region  mean_by_brand  median_by_brand  \\\n",
       "id                                                                    \n",
       "1            2         3200      21    7498.480243             2500   \n",
       "2            5         6500      12    7305.882353             6500   \n",
       "3            2         2100       9    7498.480243             2500   \n",
       "4            2         2000       4    7498.480243             2500   \n",
       "5            2         6100      21    7498.480243             2500   \n",
       "\n",
       "    min_by_brand  max_by_brand  mean_by_region  median_by_region  \\\n",
       "id                                                                 \n",
       "1            100        180000     8638.888889              3100   \n",
       "2            500         22400     5608.333333              5000   \n",
       "3            100        180000     5650.000000              4700   \n",
       "4            100        180000     2587.692308              1500   \n",
       "5            100        180000     8638.888889              3100   \n",
       "\n",
       "    min_by_region  max_by_region  \n",
       "id                                \n",
       "1             100         103600  \n",
       "2            1100          13000  \n",
       "3             500          18800  \n",
       "4             100          46200  \n",
       "5             100         103600  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['region', 'auto_brand'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.drop(['region', 'auto_brand'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compensated</th>\n",
       "      <th>mean_by_brand</th>\n",
       "      <th>median_by_brand</th>\n",
       "      <th>min_by_brand</th>\n",
       "      <th>max_by_brand</th>\n",
       "      <th>mean_by_region</th>\n",
       "      <th>median_by_region</th>\n",
       "      <th>min_by_region</th>\n",
       "      <th>max_by_region</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3200</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>8638.888889</td>\n",
       "      <td>3100</td>\n",
       "      <td>100</td>\n",
       "      <td>103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6500</td>\n",
       "      <td>7305.882353</td>\n",
       "      <td>6500</td>\n",
       "      <td>500</td>\n",
       "      <td>22400</td>\n",
       "      <td>5608.333333</td>\n",
       "      <td>5000</td>\n",
       "      <td>1100</td>\n",
       "      <td>13000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2100</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>5650.000000</td>\n",
       "      <td>4700</td>\n",
       "      <td>500</td>\n",
       "      <td>18800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>2587.692308</td>\n",
       "      <td>1500</td>\n",
       "      <td>100</td>\n",
       "      <td>46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6100</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>8638.888889</td>\n",
       "      <td>3100</td>\n",
       "      <td>100</td>\n",
       "      <td>103600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    compensated  mean_by_brand  median_by_brand  min_by_brand  max_by_brand  \\\n",
       "id                                                                            \n",
       "1          3200    7498.480243             2500           100        180000   \n",
       "2          6500    7305.882353             6500           500         22400   \n",
       "3          2100    7498.480243             2500           100        180000   \n",
       "4          2000    7498.480243             2500           100        180000   \n",
       "5          6100    7498.480243             2500           100        180000   \n",
       "\n",
       "    mean_by_region  median_by_region  min_by_region  max_by_region  \n",
       "id                                                                  \n",
       "1      8638.888889              3100            100         103600  \n",
       "2      5608.333333              5000           1100          13000  \n",
       "3      5650.000000              4700            500          18800  \n",
       "4      2587.692308              1500            100          46200  \n",
       "5      8638.888889              3100            100         103600  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compensated</th>\n",
       "      <th>mean_by_brand</th>\n",
       "      <th>median_by_brand</th>\n",
       "      <th>min_by_brand</th>\n",
       "      <th>max_by_brand</th>\n",
       "      <th>mean_by_region</th>\n",
       "      <th>median_by_region</th>\n",
       "      <th>min_by_region</th>\n",
       "      <th>max_by_region</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6000</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>8638.888889</td>\n",
       "      <td>3100</td>\n",
       "      <td>100</td>\n",
       "      <td>103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>9988.235294</td>\n",
       "      <td>2000</td>\n",
       "      <td>300</td>\n",
       "      <td>145000</td>\n",
       "      <td>19044.444444</td>\n",
       "      <td>21000</td>\n",
       "      <td>1000</td>\n",
       "      <td>49200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>8806.451613</td>\n",
       "      <td>8000</td>\n",
       "      <td>500</td>\n",
       "      <td>32000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4600</td>\n",
       "      <td>7498.480243</td>\n",
       "      <td>2500</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "      <td>15056.410256</td>\n",
       "      <td>7600</td>\n",
       "      <td>100</td>\n",
       "      <td>180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3000</td>\n",
       "      <td>9988.235294</td>\n",
       "      <td>2000</td>\n",
       "      <td>300</td>\n",
       "      <td>145000</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>1650</td>\n",
       "      <td>300</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    compensated  mean_by_brand  median_by_brand  min_by_brand  max_by_brand  \\\n",
       "id                                                                            \n",
       "1          6000    7498.480243             2500           100        180000   \n",
       "2          3000    9988.235294             2000           300        145000   \n",
       "3          5000    7498.480243             2500           100        180000   \n",
       "4          4600    7498.480243             2500           100        180000   \n",
       "5          3000    9988.235294             2000           300        145000   \n",
       "\n",
       "    mean_by_region  median_by_region  min_by_region  max_by_region  \n",
       "id                                                                  \n",
       "1      8638.888889              3100            100         103600  \n",
       "2     19044.444444             21000           1000          49200  \n",
       "3      8806.451613              8000            500          32000  \n",
       "4     15056.410256              7600            100         180000  \n",
       "5      1650.000000              1650            300           3000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Определите с помощью случайного леса важность имеющихся признаков. Здесь можно брать много (например, 1000) глубоких (например, глубины 5) деревьев решений. Используйте параметр random_state=42.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>compensated</th>\n",
       "      <td>0.654327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_by_region</th>\n",
       "      <td>0.084812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_by_region</th>\n",
       "      <td>0.084311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_by_region</th>\n",
       "      <td>0.055484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_by_brand</th>\n",
       "      <td>0.027447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_by_brand</th>\n",
       "      <td>0.026239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_by_brand</th>\n",
       "      <td>0.025839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_by_region</th>\n",
       "      <td>0.021073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_by_brand</th>\n",
       "      <td>0.020468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Importance\n",
       "compensated         0.654327\n",
       "median_by_region    0.084812\n",
       "mean_by_region      0.084311\n",
       "max_by_region       0.055484\n",
       "max_by_brand        0.027447\n",
       "median_by_brand     0.026239\n",
       "mean_by_brand       0.025839\n",
       "min_by_region       0.021073\n",
       "min_by_brand        0.020468"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1000,\n",
    "                               max_depth=5,\n",
    "                               random_state=42)\n",
    "forest.fit(train_df, y)\n",
    "pd.DataFrame(forest.feature_importances_,\n",
    "             index=train_df.columns,\n",
    "            columns=['Importance']).sort(['Importance'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите на имеющейся выборке с 3 \"лучшими\" признаками случайный лес, переберите параметры глубины дерева от 1 до 4, а число деревьев - 100 или 500. Используйте 5-кратную кросс-валидацию и параметр random_state=42.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 500], 'max_depth': [1, 2, 3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree params for grid search\n",
    "tree_params = {'n_estimators': [100, 500],\n",
    "               'max_depth': list(range(1,4)),}\n",
    "               #'min_samples_leaf': list(range(1,5))}\n",
    "\n",
    "locally_best_clf = GridSearchCV(RandomForestClassifier(random_state=42), \n",
    "                                 tree_params, \n",
    "                                 verbose=True, n_jobs=1, cv=5)\n",
    "locally_best_clf.fit(train_df[['compensated', 'median_by_region', 'mean_by_region']], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locally_best_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locally_best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70991432068543447"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locally_best_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучите на всей выборке случайный лес, с лучшими параметрами, определенными ранее. Используйте также параметр random_state=42.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(n_estimators=100,\n",
    "                                          max_depth=2,\n",
    "                                     random_state=42)\n",
    "final_model.fit(train_df[['compensated', \n",
    "                          'median_by_region', 'mean_by_region']], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание выплат для тестовой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте прогноз для объектов тестовой выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_labels = final_model.predict(test_df[['compensated', \n",
    "                                                'median_by_region', \n",
    "                                                'mean_by_region']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сравним сразу с ответами (в качестве демонстрации, в реальной задаче ответы, конечно, неизвестны).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751937984496\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "try:\n",
    "    expected_labels_df = pd.read_csv(\"../../data/car_insurance_test_labels.csv\",\n",
    "                                     header=0, index_col=0)\n",
    "    expected_labels = expected_labels_df['too_much']\n",
    "    print(roc_auc_score(predicted_labels, expected_labels))\n",
    "except OSError:\n",
    "    print(\"You shouldn't know the answers, but this results in 0.752 ROC AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите ответы в csv-файл и отправьте решение на Kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn predictions into data frame and save as csv file\n",
    "predicted_df = pd.DataFrame(predicted_labels,\n",
    "                            index = np.arange(1, test_df.shape[0] + 1),\n",
    "                            columns=[\"too_much\"])\n",
    "predicted_df.to_csv(\"../../output/rf_with_region_n100_depth2.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**для Weka**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_nominal = pd.Series(['OK' if label == 0 else 'too_much' \n",
    "                       for label in y], name='target', \n",
    "                      index=range(1, y.shape[0]+1))\n",
    "test_labels = pd.read_csv(\"../../data/car_insurance_test_labels.csv\",\n",
    "        header=0, index_col=0)\n",
    "y_test_nominal = pd.Series(['OK' if label == 0 else 'too_much' \n",
    "                            for label in np.array(test_labels)], name='target', \n",
    "                      index=range(1, test_labels.shape[0]+1))\n",
    "pd.concat([train_df, y_nominal], \n",
    "          axis=1).to_csv('../../output/car_insur_train_modified.csv')\n",
    "pd.concat([test_df, y_test_nominal], \n",
    "          axis=1).to_csv('../../output/car_insur_test_modified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ссылки:\n",
    "- <a href=\"https://inclass.kaggle.com/c/hse-addprofeduc-ml-contest\">Соревнование</a> на сайте Kaggle Inclass\n",
    "- Исходное <a href=\"http://microsoftbi.ru/2015/06/06/hackathon2015ml/\">описание</a> задачи\n",
    "- [Документация](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) Scikit-learn по классу RandomForestClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "name": "lesson1_part3_kaggle_inclass_contest.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
