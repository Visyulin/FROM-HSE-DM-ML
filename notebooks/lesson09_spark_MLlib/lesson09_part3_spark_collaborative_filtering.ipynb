{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ml_theme.png\">\n",
    "# Дополнительное профессиональное <br> образование НИУ ВШЭ\n",
    "#### Программа \"Машинное обучение и майнинг данных\"\n",
    "<img src=\"../../img/faculty_logo.jpg\" height=\"240\" width=\"240\">\n",
    "## Автор материала: преподаватель Факультета Компьютерных Наук НИУ ВШЭ Кашницкий Юрий\n",
    "</center>\n",
    "Основано на материалах <a href=\"https://courses.edx.org/courses/BerkeleyX/CS100.1x/1T2015/info\">курса</a> по Apache Spark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Занятие 9. Машинное обучение с Apache Spark\n",
    "## Часть 3. Прогнозирование рейтинга фильма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png) ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "#### Рекомендация фильмов пользователю. Для начала что-то простое, затем используем метод Alternating Least Squares библиотеки [Spark MLlib](https://spark.apache.org/mllib/)\n",
    "#### Для демонстрации используем 500,000 рейтингов из набора [movielens](http://grouplens.org/datasets/movielens/).\n",
    "#### План:\n",
    "#### *Часть 0*: Основы\n",
    "#### *Часть 1*: Простые рекомендации\n",
    "#### *Часть 2*: Коллаборативная фильтрация\n",
    "#### *Часть 3*: Проверка алгоритма \"на себе\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для тестирования результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# from test_helper import Test\n",
    "\n",
    "baseDir = os.path.join('../../data/')\n",
    "\n",
    "ratingsFilename = os.path.join(baseDir, 'ratings.dat')\n",
    "moviesFilename = os.path.join(baseDir, 'movies.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3883"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawMovies = sc.textFile(moviesFilename)\n",
    "moviesRDD = rawMovies.map(get_movie_tuple).cache()\n",
    "moviesRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Часть 0: Основы**\n",
    "#### Каждая строка файла `ratings.dat.gz` имеет вид:\n",
    "####   `UserID::MovieID::Rating::Timestamp`\n",
    "#### Каждая строка файла `movies.dat` имеет вид:\n",
    "####   `MovieID::Title::Genres`\n",
    "#### Формат поля `Genres`:\n",
    "####   `Genres1|Genres2|Genres3|...`\n",
    "* #### Для каждой строки файла с рейтингами создаем кортеж (UserID, MovieID, Rating).\n",
    "* #### Для каждой строки файла с фильмами создаем кортеж (MovieID, Title)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 487650 ratings and 3883 movies in the datasets\n",
      "Ratings: [(1, 1193, 5.0), (1, 914, 3.0), (1, 2355, 5.0)]\n",
      "Movies: [(1, u'Toy Story (1995)'), (2, u'Jumanji (1995)'), (3, u'Grumpier Old Men (1995)')]\n"
     ]
    }
   ],
   "source": [
    "numPartitions = 2\n",
    "rawRatings = sc.textFile(ratingsFilename).repartition(numPartitions)\n",
    "rawMovies = sc.textFile(moviesFilename)\n",
    "\n",
    "def get_ratings_tuple(entry):\n",
    "    \"\"\" Parse a line in the ratings dataset\n",
    "    Args:\n",
    "        entry (str): a line in the ratings dataset in the form of UserID::MovieID::Rating::Timestamp\n",
    "    Returns:\n",
    "        tuple: (UserID, MovieID, Rating)\n",
    "    \"\"\"\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), int(items[1]), float(items[2])\n",
    "\n",
    "\n",
    "def get_movie_tuple(entry):\n",
    "    \"\"\" Parse a line in the movies dataset\n",
    "    Args:\n",
    "        entry (str): a line in the movies dataset in the form of MovieID::Title::Genres\n",
    "    Returns:\n",
    "        tuple: (MovieID, Title)\n",
    "    \"\"\"\n",
    "    items = entry.split('::')\n",
    "    return int(items[0]), items[1]\n",
    "\n",
    "\n",
    "ratingsRDD = rawRatings.map(get_ratings_tuple).cache()\n",
    "moviesRDD = rawMovies.map(get_movie_tuple).cache()\n",
    "\n",
    "ratingsCount = ratingsRDD.count()\n",
    "moviesCount = moviesRDD.count()\n",
    "\n",
    "print('There are %s ratings and %s movies in the datasets' % (ratingsCount, moviesCount))\n",
    "print('Ratings: %s' % ratingsRDD.take(3))\n",
    "print('Movies: %s' % moviesRDD.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создадим функцию для сортировки и по ключам, и по значениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, u'alpha'), (1, u'delta'), (1, u'epsilon'), (2, u'alpha'), (2, u'beta'), (3, u'alpha')]\n",
      "[(1, u'alpha'), (1, u'delta'), (1, u'epsilon'), (2, u'alpha'), (2, u'beta'), (3, u'alpha')]\n"
     ]
    }
   ],
   "source": [
    "def sortFunction(tuple):\n",
    "    \"\"\" Construct the sort string (does not perform actual sorting)\n",
    "    Args:\n",
    "        tuple: (rating, MovieName)\n",
    "    Returns:\n",
    "        sortString: the value to sort with, 'rating MovieName'\n",
    "    \"\"\"\n",
    "    key = unicode('%.3f' % tuple[0])\n",
    "    value = tuple[1]\n",
    "    return (key + ' ' + value)\n",
    "\n",
    "tmp1 = [(1, u'alpha'), (2, u'alpha'), (2, u'beta'), (3, u'alpha'), (1, u'epsilon'), (1, u'delta')]\n",
    "tmp2 = [(1, u'delta'), (2, u'alpha'), (2, u'beta'), (3, u'alpha'), (1, u'epsilon'), (1, u'alpha')]\n",
    "\n",
    "oneRDD = sc.parallelize(tmp1)\n",
    "twoRDD = sc.parallelize(tmp2)\n",
    "\n",
    "print(oneRDD.sortBy(sortFunction, True).collect())\n",
    "print(twoRDD.sortBy(sortFunction, True).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Часть 1: Простые рекомендации**\n",
    "#### Простой способ - рекомендовать фильмы с высоким средним рейтингом. Здесь найдем средние рейтинги 20 фильмов с более чем 500 оценками. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1a) Средние рeйтинги фильмов**\n",
    "#### `getCountsAndAverages()` принимает кортеж вида (MovieID, (Rating1, Rating2, Rating3, ...)) и возвращает кортеж вида (MovieID, (число оценок, средняя оценка))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCountsAndAverages(IDandRatingsTuple):\n",
    "    \"\"\" Calculate average rating\n",
    "    Args:\n",
    "        IDandRatingsTuple: a single tuple of (MovieID, (Rating1, Rating2, Rating3, ...))\n",
    "    Returns:\n",
    "        tuple: a tuple of (MovieID, (number of ratings, averageRating))\n",
    "    \"\"\"\n",
    "    movie_id, ratings = IDandRatingsTuple\n",
    "    num_ratings = len(ratings)\n",
    "    avg_rating  = float(sum(ratings)) / num_ratings\n",
    "    return (movie_id, (num_ratings, avg_rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1b) Фильмы с высокими средними оценками**\n",
    "\n",
    "#### Шаги:\n",
    "* ####  `ratingsRDD` состоит из кортежей вида (UserID, MovieID, Rating). Создадим RDD вида (MovieID, итератор по оценкам фильма с номером MovieID).\n",
    "* #### С помощью `getCountsAndAverages()` посчитаем число оценок и среднюю оценку каждого фильма:  (MovieID, (число оценок, средняя оценка)).\n",
    "* #### Вместо ID фильмов хотим видеть их названия. В конце получится RDD вида  (средняя оценка, название фильма, число оценок). Например, `[(3.6818181818181817, u'Happiest Millionaire, The (1967)', 22), (3.0468227424749164, u'Grumpier Old Men (1995)', 299), (2.882978723404255, u'Hocus Pocus (1993)', 94)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieIDsWithRatingsRDD: [(2, <pyspark.resultiterable.ResultIterable object at 0x7ff8028ffed0>), (4, <pyspark.resultiterable.ResultIterable object at 0x7ff8029bb490>), (6, <pyspark.resultiterable.ResultIterable object at 0x7ff8029bb1d0>)]\n",
      "\n",
      "movieIDsWithAvgRatingsRDD: [(2, (332, 3.174698795180723)), (4, (71, 2.676056338028169)), (6, (442, 3.7918552036199094))]\n",
      "\n",
      "movieNameWithAvgRatingsRDD: [(3.5671641791044775, u'Great Mouse Detective, The (1986)', 67), (3.763948497854077, u'Moonstruck (1987)', 466), (2.676056338028169, u'Waiting to Exhale (1995)', 71)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From ratingsRDD with tuples of (UserID, MovieID, Rating) create an RDD with tuples of\n",
    "# the (MovieID, iterable of Ratings for that MovieID)\n",
    "movieIDsWithRatingsRDD = (ratingsRDD\n",
    "                          .map(lambda (user_id, movie_id, rating): (movie_id, rating))\n",
    "                         .groupByKey())\n",
    "print('movieIDsWithRatingsRDD: %s\\n' % movieIDsWithRatingsRDD.take(3))\n",
    "\n",
    "# Using `movieIDsWithRatingsRDD`, compute the number of ratings and average rating for each movie to\n",
    "# yield tuples of the form (MovieID, (number of ratings, average rating))\n",
    "movieIDsWithAvgRatingsRDD = (movieIDsWithRatingsRDD\n",
    "                             .map(lambda (movie_id, rating): getCountsAndAverages((movie_id, rating))))\n",
    "print('movieIDsWithAvgRatingsRDD: %s\\n' % movieIDsWithAvgRatingsRDD.take(3))\n",
    "\n",
    "# To `movieIDsWithAvgRatingsRDD`, apply RDD transformations that use `moviesRDD` to get the movie\n",
    "# names for `movieIDsWithAvgRatingsRDD`, yielding tuples of the form\n",
    "# (average rating, movie name, number of ratings)\n",
    "movieNameWithAvgRatingsRDD = (moviesRDD\n",
    "                              .join(movieIDsWithAvgRatingsRDD)\n",
    "                             .map(lambda (movie_id, (movie_name, (num_ratings, avg_rating))): \n",
    "                                                    (avg_rating, movie_name, num_ratings)))\n",
    "print('movieNameWithAvgRatingsRDD: %s\\n' % movieNameWithAvgRatingsRDD.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1c) Фильмы с самыми высокими рейтингами, основанными более чем на 500 оценках **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies with highest ratings: [(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088), (4.515798462852263, u\"Schindler's List (1993)\", 1171), (4.512893982808023, u'Godfather, The (1972)', 1047), (4.510460251046025, u'Raiders of the Lost Ark (1981)', 1195), (4.505415162454874, u'Usual Suspects, The (1995)', 831), (4.457256461232604, u'Rear Window (1954)', 503), (4.45468509984639, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 651), (4.43953006219765, u'Star Wars: Episode IV - A New Hope (1977)', 1447), (4.4, u'Sixth Sense, The (1999)', 1110), (4.394285714285714, u'North by Northwest (1959)', 700), (4.379506641366224, u'Citizen Kane (1941)', 527), (4.375, u'Casablanca (1942)', 776), (4.363975155279503, u'Godfather: Part II, The (1974)', 805), (4.358816276202219, u\"One Flew Over the Cuckoo's Nest (1975)\", 811), (4.358173076923077, u'Silence of the Lambs, The (1991)', 1248), (4.335826477187734, u'Saving Private Ryan (1998)', 1337), (4.326241134751773, u'Chinatown (1974)', 564), (4.325383304940375, u'Life Is Beautiful (La Vita \\ufffd bella) (1997)', 587), (4.324110671936759, u'Monty Python and the Holy Grail (1974)', 759), (4.3096, u'Matrix, The (1999)', 1250)]\n"
     ]
    }
   ],
   "source": [
    "# Apply an RDD transformation to `movieNameWithAvgRatingsRDD` to limit the results to movies with\n",
    "# ratings from more than 500 people. We then use the `sortFunction()` helper function to sort by the\n",
    "# average rating to get the movies in order of their rating (highest rating first)\n",
    "movieLimitedAndSortedByRatingRDD = (movieNameWithAvgRatingsRDD\n",
    "                                    .filter(lambda (avg_rating, movie_name, num_ratings):\n",
    "                                           num_ratings > 500)\n",
    "                                    .sortBy(sortFunction, ascending=False))\n",
    "print('Movies with highest ratings: %s' % movieLimitedAndSortedByRatingRDD.take(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Часть 2: Коллаборативная фильтрация**\n",
    "#### Основное допущение коллаборативной фильтрации: если Кирилл относится к какому-то предмету (фильму, книге) так же, как Федя,  то скорее его отношение и к другому предмету ближе ко мнению Феди, чем ко мнению случайно выбранного из толпы человека.\n",
    "#### Анимация из [Wikipedia](https://en.wikipedia.org/?title=Collaborative_filtering)\n",
    "![collaborative filtering](https://courses.edx.org/c4x/BerkeleyX/CS100.1x/asset/Collaborative_filtering.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для рекомендации фильмов начинаем  с матрицы оценок фильмов пользователями. Матрица обозначена красным цветом на картинке ниже. Каждый столбец представляет пользователя (зеленый), а каждая строка - какой-то фильм (синий).\n",
    "\n",
    "#### Идея в том, чтобы приближенно представить эту матрицу в виде произведения двух других матриц, суть которых - некоторые признаки пользователей (зеленая матрица) и некоторые признаки фильмов (синяя матрица).\n",
    "![factorization](http://spark-mooc.github.io/web-assets/images/matrix_factorization.png)\n",
    "#### Матрицы хочется подобрать так, чтобы минимизировать ошибку в оценках для пар (пользователь, фильм), где оценка известна. Метод [Alternating Least Squares](http://stanford.edu/~rezab/dao/notes/lec14.pdf) делает это так: сначала одна из матриц (признаки пользователей или фильмов) заполняется случайным числами, потом значения второй матрицы подбираются решением задачи оптимизации. Потом наоборот. И так далее до сходимости. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2a) Создание обучающей выборки**\n",
    "#### Используем [randomSplit()](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) для разбиения данных на обучающую (`trainingRDD`), проверочную (`validationRDD`) и тестовую (`testRDD`) выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 292716, validation: 96902, test: 98032\n",
      "\n",
      "[(1, 914, 3.0), (1, 2355, 5.0), (1, 595, 5.0)]\n",
      "[(1, 1287, 5.0), (1, 594, 4.0), (1, 1270, 5.0)]\n",
      "[(1, 1193, 5.0), (1, 2398, 4.0), (1, 1035, 5.0)]\n"
     ]
    }
   ],
   "source": [
    "trainingRDD, validationRDD, testRDD = ratingsRDD.randomSplit([6, 2, 2], seed=0L)\n",
    "\n",
    "print('Training: %s, validation: %s, test: %s\\n' % (trainingRDD.count(),\n",
    "                                                    validationRDD.count(),\n",
    "                                                    testRDD.count()))\n",
    "print(trainingRDD.take(3))\n",
    "print(validationRDD.take(3))\n",
    "print(testRDD.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2b) Среднеквадратичная ошибка (RMSE)**\n",
    "#### Пусть имеются  `predictedRDD` и `actualRDD`, каждый вида (UserID, MovieID, Rating). Тогда  $ RMSE = \\sqrt{\\frac{\\sum_{i = 1}^{n} (x_i - y_i)^2}{n}}$, где $x_i$ и $y_i$ - оценки (Rating) из `predictedRDD` и `actualRDD` соответственно, $n$ - число троек в этих RDD.\n",
    "#### Шаги:\n",
    "* #### Преобразовать `predictedRDD` и `actualRDD` к виду ((UserID, MovieID), Rating)\n",
    "\n",
    "* #### Для совпадающих пар (UserID, MovieID) посчитать квадраты разниц оценок  $ (x_i - y_i)^2$. Здесь важно не использовать метод `collect()`, потому что результаты такой операции (полученный список) могут не поместиться на одной машине. \n",
    "* #### Посчитать $$ SE = \\sum_{i = 1}^{n} (x_i - y_i)^2 $$\n",
    "* #### Найти *n* - число пар, по которым была посчитана сумма квадратов разниц оценок. \n",
    "* #### Посчитать RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for test dataset (should be 1.22474487139): 1.22474487139\n",
      "Error for test dataset2 (should be 3.16227766017): 3.16227766017\n",
      "Error for testActual dataset (should be 0.0): 0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def computeError(predictedRDD, actualRDD):\n",
    "    \"\"\" Compute the root mean squared error between predicted and actual\n",
    "    Args:\n",
    "        predictedRDD: predicted ratings for each movie and each user where each entry is in the form\n",
    "                      (UserID, MovieID, Rating)\n",
    "        actualRDD: actual ratings where each entry is in the form (UserID, MovieID, Rating)\n",
    "    Returns:\n",
    "        RSME (float): computed RSME value\n",
    "    \"\"\"\n",
    "    # Transform predictedRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    predictedReformattedRDD = predictedRDD.map(lambda (u_id, m_id, r): ((u_id, m_id), r))\n",
    "\n",
    "    # Transform actualRDD into the tuples of the form ((UserID, MovieID), Rating)\n",
    "    actualReformattedRDD = actualRDD.map(lambda (u_id, m_id, r): ((u_id, m_id), r))\n",
    "\n",
    "    # Compute the squared error for each matching entry (i.e., the same (User ID, Movie ID) in each\n",
    "    # RDD) in the reformatted RDDs using RDD transformtions - do not use collect()\n",
    "    squaredErrorsRDD = (predictedReformattedRDD\n",
    "                        .join(actualReformattedRDD)\n",
    "                        .map(lambda ((u_id, m_id), (r1, r2)): pow(r1 - r2,2))\n",
    "                        )\n",
    "\n",
    "    # Compute the total squared error - do not use collect()\n",
    "    totalError = squaredErrorsRDD.sum()\n",
    "    # Count the number of entries for which you computed the total squared error\n",
    "    numRatings = squaredErrorsRDD.count()\n",
    "\n",
    "    # Using the total squared error and the number of entries, compute the RSME\n",
    "    return math.sqrt(float(totalError) / numRatings)\n",
    "\n",
    "# sc.parallelize turns a Python list into a Spark RDD.\n",
    "testPredicted = sc.parallelize([\n",
    "    (1, 1, 5),\n",
    "    (1, 2, 3),\n",
    "    (1, 3, 4),\n",
    "    (2, 1, 3),\n",
    "    (2, 2, 2),\n",
    "    (2, 3, 4)])\n",
    "testActual = sc.parallelize([\n",
    "     (1, 2, 3),\n",
    "     (1, 3, 5),\n",
    "     (2, 1, 5),\n",
    "     (2, 2, 1)])\n",
    "testPredicted2 = sc.parallelize([\n",
    "     (2, 2, 5),\n",
    "     (1, 2, 5)])\n",
    "testError = computeError(testPredicted, testActual)\n",
    "print('Error for test dataset (should be 1.22474487139): %s' % testError)\n",
    "\n",
    "testError2 = computeError(testPredicted2, testActual)\n",
    "print('Error for test dataset2 (should be 3.16227766017): %s' % testError2)\n",
    "\n",
    "testError3 = computeError(testActual, testActual)\n",
    "print('Error for testActual dataset (should be 0.0): %s' % testError3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2c) Использование ALS.train()**\n",
    "#### Шаги:\n",
    "* #### Выбор параметров модели. Самый важный параметр метода `ALS.train()` - *rank*, число строк в матрице пользователей или, что то же самое, число столбцов в матрице фильмов. (Обычно малый ранг приводит к недообучению, а большой - к переобучению).  Будем для обучающей выборки `trainingRDD` использовать ранги 4, 8 и 12. \n",
    "* #### Создаем модель `ALS.train(trainingRDD, rank, seed=seed, iterations=iterations, lambda_=regularizationParameter)` со следующими параметрами: RDD? составленный из троек (UserID, MovieID, rating)  - обучающая выборка, ранг матриц разложения (4, 8 и 12), число итераций алгоритма и коэффициент регуляризации (будем использовать `regularizationParameter`=0.1).\n",
    "* #### Для прогноза используем `validationForPredictRDD`, составленный из пар (UserID, MovieID)  `validationRDD`.\n",
    "* #### Вычисление ошибки прогнозна рейтингов для `validationForPredictRDD` (метод [model.predictAll()](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.recommendation.MatrixFactorizationModel.predictAll)) с реальными с помощью написанной ранее функции `computeError()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.895405660311\n",
      "For rank 8 the RMSE is 0.895514822303\n",
      "For rank 12 the RMSE is 0.894980442967\n",
      "The best model was trained with rank 12\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "validationForPredictRDD = validationRDD.map(lambda (u_id, m_id, r): \n",
    "                                            (u_id, m_id))\n",
    "\n",
    "seed = 5L\n",
    "iterations = 5\n",
    "regularizationParameter = 0.1\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "minError = float('inf')\n",
    "bestRank = -1\n",
    "bestIteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingRDD, rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "    predictedRatingsRDD = model.predictAll(validationForPredictRDD)\n",
    "    error = computeError(predictedRatingsRDD, validationRDD)\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print('For rank %s the RMSE is %s' % (rank, error))\n",
    "    if error < minError:\n",
    "        minError = error\n",
    "        bestRank = rank\n",
    "\n",
    "print('The best model was trained with rank %s' % bestRank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2d) Проверка модели**\n",
    "#### Шаги:\n",
    "* #### Обучение модели на выборке `trainingRDD`  с рангом  `bestRank` и прочими.\n",
    "* #### Прогнозирование для пар (UserID, MovieID) из  `testForPredictingRDD`.\n",
    "* #### Вычисление ошибки для  `testRDD` с помощью функции `computeError`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a RMSE on the test set of 0.896040796967\n"
     ]
    }
   ],
   "source": [
    "myModel = ALS.train(trainingRDD, bestRank, seed=seed, iterations=iterations,\n",
    "                    lambda_=regularizationParameter)\n",
    "testForPredictingRDD = testRDD.map(lambda (u_id, m_id, r): (u_id, m_id))\n",
    "predictedTestRDD = myModel.predictAll(testForPredictingRDD)\n",
    "\n",
    "testRMSE = computeError(testRDD, predictedTestRDD)\n",
    "\n",
    "print('The model had a RMSE on the test set of %s' % testRMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(2e) Сравнение с предсказанием по среднему**\n",
    "#### Шаги:\n",
    "* #### Подсчет среднего рейтинга по каждому фильму для `trainingRDD`.\n",
    "* #### Создание троек (userID, movieID, average rating) для  `testRDD`.\n",
    "* #### Оценка с помощью `computeError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating for movies in the training set is 3.57409571052\n",
      "The RMSE on the average set is 1.12036693569\n"
     ]
    }
   ],
   "source": [
    "trainingAvgRating = trainingRDD.map(lambda (u_id, m_id, r): r).mean()\n",
    "print('The average rating for movies in the training set is %s' \n",
    "      % trainingAvgRating)\n",
    "\n",
    "testForAvgRDD = testRDD.map(lambda (u_id, m_id, r): \n",
    "                            (u_id, m_id, trainingAvgRating))\n",
    "testAvgRMSE = computeError(testRDD, testForAvgRDD)\n",
    "print('The RMSE on the average set is %s' % testAvgRMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теперь все готово для предсказания рейтинга фильмов!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Часть 3. Проверка алгоритма \"на себе\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3a) Добавление собственных оценок в `ratingsRDD`**\n",
    "#### В помощь - рейтинг самых популярных фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most rated movies:\n",
      "(average rating, movie name, number of reviews)\n",
      "(4.5349264705882355, u'Shawshank Redemption, The (1994)', 1088)\n",
      "(4.515798462852263, u\"Schindler's List (1993)\", 1171)\n",
      "(4.512893982808023, u'Godfather, The (1972)', 1047)\n",
      "(4.510460251046025, u'Raiders of the Lost Ark (1981)', 1195)\n",
      "(4.505415162454874, u'Usual Suspects, The (1995)', 831)\n",
      "(4.457256461232604, u'Rear Window (1954)', 503)\n",
      "(4.45468509984639, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 651)\n",
      "(4.43953006219765, u'Star Wars: Episode IV - A New Hope (1977)', 1447)\n",
      "(4.4, u'Sixth Sense, The (1999)', 1110)\n",
      "(4.394285714285714, u'North by Northwest (1959)', 700)\n",
      "(4.379506641366224, u'Citizen Kane (1941)', 527)\n",
      "(4.375, u'Casablanca (1942)', 776)\n",
      "(4.363975155279503, u'Godfather: Part II, The (1974)', 805)\n",
      "(4.358816276202219, u\"One Flew Over the Cuckoo's Nest (1975)\", 811)\n",
      "(4.358173076923077, u'Silence of the Lambs, The (1991)', 1248)\n",
      "(4.335826477187734, u'Saving Private Ryan (1998)', 1337)\n",
      "(4.326241134751773, u'Chinatown (1974)', 564)\n",
      "(4.325383304940375, u'Life Is Beautiful (La Vita \\ufffd bella) (1997)', 587)\n",
      "(4.324110671936759, u'Monty Python and the Holy Grail (1974)', 759)\n",
      "(4.3096, u'Matrix, The (1999)', 1250)\n",
      "(4.309457579972183, u'Star Wars: Episode V - The Empire Strikes Back (1980)', 1438)\n",
      "(4.30379746835443, u'Young Frankenstein (1974)', 553)\n",
      "(4.301346801346801, u'Psycho (1960)', 594)\n",
      "(4.296438883541867, u'Pulp Fiction (1994)', 1039)\n",
      "(4.286535303776683, u'Fargo (1996)', 1218)\n",
      "(4.282367447595561, u'GoodFellas (1990)', 811)\n",
      "(4.27943661971831, u'American Beauty (1999)', 1775)\n",
      "(4.268053855569155, u'Wizard of Oz, The (1939)', 817)\n",
      "(4.267774699907664, u'Princess Bride, The (1987)', 1083)\n",
      "(4.253333333333333, u'Graduate, The (1967)', 600)\n",
      "(4.236263736263736, u'Run Lola Run (Lola rennt) (1998)', 546)\n",
      "(4.233807266982622, u'Amadeus (1984)', 633)\n",
      "(4.232558139534884, u'Toy Story 2 (1999)', 860)\n",
      "(4.232558139534884, u'This Is Spinal Tap (1984)', 516)\n",
      "(4.228494623655914, u'Almost Famous (2000)', 744)\n",
      "(4.2250755287009065, u'Christmas Story, A (1983)', 662)\n",
      "(4.216757741347905, u'Glory (1989)', 549)\n",
      "(4.213358070500927, u'Apocalypse Now (1979)', 539)\n",
      "(4.20992028343667, u'L.A. Confidential (1997)', 1129)\n",
      "(4.204733727810651, u'Blade Runner (1982)', 845)\n",
      "(4.1886120996441285, u'Sling Blade (1996)', 562)\n",
      "(4.184615384615385, u'Braveheart (1995)', 1300)\n",
      "(4.184168012924071, u'Butch Cassidy and the Sundance Kid (1969)', 619)\n",
      "(4.182509505703422, u'Good Will Hunting (1997)', 789)\n",
      "(4.166969147005445, u'Taxi Driver (1976)', 551)\n",
      "(4.162767039674466, u'Terminator, The (1984)', 983)\n",
      "(4.157545605306799, u'Reservoir Dogs (1992)', 603)\n",
      "(4.153333333333333, u'Jaws (1975)', 750)\n",
      "(4.149840595111583, u'Alien (1979)', 941)\n",
      "(4.145015105740181, u'Toy Story (1995)', 993)\n"
     ]
    }
   ],
   "source": [
    "print('Most rated movies:')\n",
    "print('(average rating, movie name, number of reviews)')\n",
    "for ratingsTuple in movieLimitedAndSortedByRatingRDD.take(50):\n",
    "    print(ratingsTuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ID пользователя 0 еще не было. Используем его. Создадим свой список с оценками фильмов - тройки вида  `(myUserID, movieID, оценка)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My movie ratings: [(0, 318, 5), (0, 858, 3), (0, 260, 2), (0, 912, 5), (0, 2028, 3), (0, 2571, 3), (0, 2324, 5), (0, 292, 1), (0, 1225, 5), (0, 1617, 2)]\n"
     ]
    }
   ],
   "source": [
    "myUserID = 0\n",
    "\n",
    "# Note that the movie IDs are the *last* number on each line. A common error was to use the number of ratings as the movie ID.\n",
    "myRatedMovies = [\n",
    "     (myUserID, 318, 5),\n",
    "    (myUserID, 858, 3),\n",
    "    (myUserID, 260, 2),\n",
    "    (myUserID, 912, 5),\n",
    "    (myUserID, 2028, 3),\n",
    "    (myUserID, 2571, 3),\n",
    "    (myUserID, 2324, 5),\n",
    "    (myUserID, 292, 1),\n",
    "    (myUserID, 1225, 5),\n",
    "    (myUserID, 1617, 2),\n",
    "    (myUserID, 111, 5),\n",
    "    (myUserID, 1704, 5),\n",
    "    (myUserID, 1240, 3),\n",
    "    (myUserID, 1387, 2)\n",
    "     # The format of each line is (myUserID, movie ID, your rating)\n",
    "     # For example, to give the movie \"Star Wars: Episode IV - A New Hope (1977)\" a five rating, you would add the following line:\n",
    "     #   (myUserID, 260, 5),\n",
    "    ]\n",
    "\n",
    "myRatingsRDD = sc.parallelize(myRatedMovies)\n",
    "print('My movie ratings: %s' % myRatingsRDD.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3b) Добавление собственных оценок в обучающую выборку**\n",
    "#### Для этого используем преобразование [union()](http://spark.apache.org/docs/latest/api/python/pyspark.rdd.RDD-class.html#union)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset now has 14 more entries than the original training dataset\n"
     ]
    }
   ],
   "source": [
    "trainingWithMyRatingsRDD = trainingRDD.union(myRatingsRDD)\n",
    "\n",
    "print('The training dataset now has %s more entries than the original training dataset' %\n",
    "       (trainingWithMyRatingsRDD.count() - trainingRDD.count()))\n",
    "assert (trainingWithMyRatingsRDD.count() - trainingRDD.count()) == myRatingsRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3c) Обучение модели с добавленными оценками**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myRatingsModel = ALS.train(trainingWithMyRatingsRDD, bestRank, \n",
    "                           seed=seed, iterations=iterations,\n",
    "                           lambda_=regularizationParameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3d) Подсчет RMSE для новой модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a RMSE on the test set of 0.895986406404\n"
     ]
    }
   ],
   "source": [
    "predictedTestMyRatingsRDD = myRatingsModel.predictAll(testForPredictingRDD)\n",
    "testRMSEMyRatings = computeError(testRDD, predictedTestMyRatingsRDD)\n",
    "print('The model had a RMSE on the test set of %s' % testRMSEMyRatings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3e) Предсказание оценок**\n",
    "#### Шаги:\n",
    "* #### Используя список `myRatedMovies`, преобразуем `moviesRDD` к виду (myUserID, Movie ID) с фильмами, не оцененными пользователем.\n",
    "* #### Для прогноза используем `myUnratedMoviesRDD` и  myRatingsModel.predictAll()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rating(user=0, product=3586, rating=1.9539098104725605), Rating(user=0, product=1084, rating=3.372458509086949), Rating(user=0, product=1410, rating=2.6245710967990514), Rating(user=0, product=3456, rating=3.1959902790419363), Rating(user=0, product=3702, rating=2.5641995134422624)]\n"
     ]
    }
   ],
   "source": [
    "myRatedMoviesRDD = myRatingsRDD.map(lambda (m_id, m_name, r): (m_id, m_name))\n",
    "\n",
    "myUnratedMoviesRDD = (moviesRDD\n",
    "                      .map(lambda (m_id, m_name): (myUserID, m_id))\n",
    "                     .subtract(myRatedMoviesRDD))\n",
    "\n",
    "# Use the input RDD, myUnratedMoviesRDD, with myRatingsModel.predictAll() to predict your ratings for the movies\n",
    "predictedRatingsRDD = myRatingsModel.predictAll(myUnratedMoviesRDD)\n",
    "print(predictedRatingsRDD.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(3f) Рекомендация фильмов**\n",
    "#### Отберем 25 фильмов с лучшими предсказанными оценками.\n",
    "#### Шаги:\n",
    "* #### Отбор фильмов в большим числом оценок (например, больше 75)\n",
    "* #### Преобразуем `predictedRatingsRDD` в RDD вида (Movie ID, Predicted Rating): `[(3456, -0.5501005376936687), (1080, 1.5885892024487962), (320, -3.7952255522487865)]`\n",
    "* #### С помощью `predictedRDD` и `movieCountsRDD` получим RDD вида (Movie ID, (предсказанный рейтинг, число оценок)): `[(2050, (0.6694097486155939, 44)), (10, (5.29762541533513, 418)), (2060, (0.5055259373841172, 97))]`\n",
    "* #### С помощью `predictedWithCountsRDD` и `moviesRDD` получим RDD вида (предсказанный рейтинг, название фильма, число оценок) для фильмов с более чем 75 оценками. Например: `[(7.983121900375243, u'Under Siege (1992)'), (7.9769201864261285, u'Fifth Element, The (1997)')]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My highest rated movies as predicted (for movies with more than 75 reviews):\n",
      "(171, u'Mr. Smith Goes to Washington (1939)', 4.507688210898011)\n",
      "(170, u\"Sophie's Choice (1982)\", 4.359257688882978)\n",
      "(100, u'Wings of Desire (Der Himmel \\ufffdber Berlin) (1987)', 4.325775731314393)\n",
      "(451, u'To Kill a Mockingbird (1962)', 4.251001290459945)\n",
      "(811, u\"One Flew Over the Cuckoo's Nest (1975)\", 4.229691012313029)\n",
      "(129, u'City Lights (1931)', 4.224421324060318)\n",
      "(306, u'Harold and Maude (1971)', 4.221661171431236)\n",
      "(124, u'Bicycle Thief, The (Ladri di biciclette) (1948)', 4.2067631775228005)\n",
      "(246, u'Ordinary People (1980)', 4.184303651854811)\n",
      "(188, u'Smoke Signals (1998)', 4.160401980982678)\n",
      "(103, u'Kolya (1996)', 4.136599131505147)\n",
      "(254, u'On the Waterfront (1954)', 4.117229509486224)\n",
      "(87, u'400 Blows, The (Les Quatre cents coups) (1959)', 4.104632319196774)\n",
      "(184, u'Breaker Morant (1980)', 4.075305851663523)\n",
      "(373, u'Do the Right Thing (1989)', 4.044654556356583)\n",
      "(229, u'Postino, Il (The Postman) (1994)', 4.0370215752797725)\n",
      "(318, u'Close Shave, A (1995)', 4.008838821586602)\n",
      "(222, u'Grand Day Out, A (1992)', 4.00179318900218)\n",
      "(257, u'Room with a View, A (1986)', 3.996492934814306)\n",
      "(317, u'Deer Hunter, The (1978)', 3.9946643644133664)\n",
      "(400, u'West Side Story (1961)', 3.993694063262071)\n",
      "(242, u'Grapes of Wrath, The (1940)', 3.9913530912455877)\n",
      "(136, u'Auntie Mame (1958)', 3.985912301990139)\n",
      "(1171, u\"Schindler's List (1993)\", 3.9798396099945075)\n",
      "(84, u'And the Band Played On (1993)', 3.9795835672699607)\n"
     ]
    }
   ],
   "source": [
    "# Transform movieIDsWithAvgRatingsRDD from part (1b), which has the form (MovieID, (number of ratings, average rating)), \n",
    "# into and RDD of the form (MovieID, number of ratings)\n",
    "movieCountsRDD = movieIDsWithAvgRatingsRDD.map(lambda (m_id, (num_r, avg_r)): \n",
    "                                               (m_id, num_r))\n",
    "\n",
    "# Transform predictedRatingsRDD into an RDD with entries that are pairs of the form (Movie ID, Predicted Rating)\n",
    "predictedRDD = predictedRatingsRDD.map(lambda rating: (rating.product, \n",
    "                                                       rating.rating)) \n",
    "\n",
    "# Use RDD transformations with predictedRDD and movieCountsRDD to yield an RDD with tuples of the form \n",
    "# (Movie ID, (Predicted Rating, number of ratings))\n",
    "predictedWithCountsRDD  = (predictedRDD\n",
    "                           .join(movieCountsRDD))\n",
    "\n",
    "\n",
    "#Use RDD transformations with PredictedWithCountsRDD and moviesRDD to yield an RDD with tuples of the form \n",
    "#(Predicted Rating, Movie Name, number of ratings), for movies with more than 75 ratings\n",
    "ratingsWithNamesRDD = (moviesRDD\n",
    "                       .join(predictedWithCountsRDD.filter(lambda (id, (rat, num_r)): num_r > 75))\n",
    "                       .map(lambda (movie_id, \n",
    "                                    (movie_name, (num_ratings, avg_rating))): \n",
    "                                    (avg_rating, movie_name, num_ratings)))\n",
    "\n",
    "predictedHighestRatedMovies = ratingsWithNamesRDD.takeOrdered(25, \n",
    "                                                              key=lambda x: -x[2])\n",
    "print('My highest rated movies as predicted (for movies with more than 75 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, predictedHighestRatedMovies)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "name": "lesson11_part4_spark_collaborative_filtering.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
